<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>CUDA Lab: Sum of Squares &amp; Matrix Multiplication | tinylcy</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">CUDA Lab: Sum of Squares &amp; Matrix Multiplication</h1><a id="logo" href="/.">tinylcy</a><p class="description">辰洋的博客</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/timeline/"><i class="fa fa-envira"> 时间线</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="https://github.com/tinylcy"><i class="fa fa-github"> GitHub</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><link rel="stylesheet" type="text/css" href="/css/reward.css"></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">CUDA Lab: Sum of Squares &amp; Matrix Multiplication</h1><div class="post-meta">Oct 16, 2017<script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-disqus-identifier="2017/10/16/CUDA-Lab-Sum-of-Squares-Matrix-Multiplication/" href="/2017/10/16/CUDA-Lab-Sum-of-Squares-Matrix-Multiplication/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#CUDA安装"><span class="toc-number">1.</span> <span class="toc-text">CUDA安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CPU-amp-GPU"><span class="toc-number">2.</span> <span class="toc-text">CPU & GPU</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CUDA架构"><span class="toc-number">3.</span> <span class="toc-text">CUDA架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Section-1-Sum-of-Squares"><span class="toc-number">4.</span> <span class="toc-text">Section 1: Sum of Squares</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-1-CUDA初始化"><span class="toc-number">4.1.</span> <span class="toc-text">Step 1: CUDA初始化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-2-CUDA核函数"><span class="toc-number">4.2.</span> <span class="toc-text">Step 2: CUDA核函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-3-执行核函数"><span class="toc-number">4.3.</span> <span class="toc-text">Step 3: 执行核函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-4-评估程序表现"><span class="toc-number">4.4.</span> <span class="toc-text">Step 4: 评估程序表现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-5-串行程序并行化"><span class="toc-number">4.5.</span> <span class="toc-text">Step 5: 串行程序并行化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-6-改进显存存取模式"><span class="toc-number">4.6.</span> <span class="toc-text">Step 6: 改进显存存取模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-7-进一步并行"><span class="toc-number">4.7.</span> <span class="toc-text">Step 7: 进一步并行</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-8-共享内存和线程同步"><span class="toc-number">4.8.</span> <span class="toc-text">Step 8: 共享内存和线程同步</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Step-9-树状加法"><span class="toc-number">4.9.</span> <span class="toc-text">Step 9: 树状加法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Section-2-Matrix-Multiplication"><span class="toc-number">5.</span> <span class="toc-text">Section 2: Matrix Multiplication</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#参考"><span class="toc-number">6.</span> <span class="toc-text">参考</span></a></li></ol></div></div><div class="post-content"><p>CUDA（Compute Unified Device Architecture）是显卡厂商 NVIDIA 推出的运算平台，是一种通用的并行计算架构，该架构使 GPU 能够解决复杂的计算问题。我们可以使用 GPU 来并行例如神经网络、图像处理等在 CPU 上运行起来比较耗时的程序，通过 GPU 并行计算可以大大提高算法的运行速度。</p>
<a id="more"></a>
<p>本实验包含两部分。</p>
<ul>
<li>第一部分（Sum of Squares）：计算数组元素的平方和，并通过不断的优化来提高程序的性能，以此来学习和理解 CUDA 编程需要注意之处。</li>
<li>第二部分（Matrix Multiplication）：利用 CUDA 实现矩阵乘法并行化。</li>
</ul>
<h3 id="CUDA安装"><a href="#CUDA安装" class="headerlink" title="CUDA安装"></a>CUDA安装</h3><ul>
<li>Visual Studio 2015 Community <a href="https://www.visualstudio.com/zh-hans/vs/older-downloads/" target="_blank" rel="external">Download</a>，CUDA Tookit 与 Visual Studio 2017 Community 暂不兼容。</li>
<li>CUDA Tookit <a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="external">Download</a>。</li>
</ul>
<p>下载 CUDA Tookit 时选择相应的操作系统及版本等平台参数。例如，在 Win10 下进行实验，参数选择如下。</p>
<p><img src="/img/2017-10-16-Image-1.png" alt=""></p>
<p><strong>注意：应先安装 Visual Studio 再安装 CUDA Tookit，因为在安装 CUDA Tookit 时会自动配置 CUDA for Visual Studio，CUDA Tookit 安装成功后可以在 Visual Studio 中创建 CUDA Project。</strong></p>
<p><img src="/img/2017-10-16-Image-2.png" alt=""></p>
<h3 id="CPU-amp-GPU"><a href="#CPU-amp-GPU" class="headerlink" title="CPU &amp; GPU"></a>CPU &amp; GPU</h3><p>下图为CPU和GPU的对比图，相比于CPU，GPU更加适用于计算强度高，多并行的计算中。GPU拥有更多的晶体管，而不是数据Cache和控制器，这样设计的意图是在并行计算过程时每个数据单元经常执行相同的程序，不需要繁琐的复杂流程控制和Cache，更需要强大的计算能力。</p>
<p><img src="/img/2017-10-16-Image-3.png" alt=""></p>
<p>使用 GPU 来进行运算工作，和使用 CPU 相比，主要有以下优势。</p>
<ul>
<li>显示芯片通常具有更大的内存带宽。例如，NVIDIA 的 GeForce 8800GTX 具有超过50GB/s 的内存带宽，而目前高阶 CPU 的内存带宽则在 10GB/s 左右。 </li>
<li>显示芯片具有更大量的执行单元。例如 GeForce 8800GTX 具有 128 个 “stream processors”，频率为 1.35GHz。CPU 频率通常较高，但是执行单元的数目则要少得多。</li>
<li>和高阶 CPU 相比，显卡的价格较为低廉。例如目前一张 GeForce 8800GT 包括512MB 内存的价格，和一颗 2.4GHz 四核心 CPU 的价格相当。 </li>
</ul>
<h3 id="CUDA架构"><a href="#CUDA架构" class="headerlink" title="CUDA架构"></a>CUDA架构</h3><p>在 CUDA 架构下，一个程序被划分为两个部分：Host 端和 Device 端。Host 端是指运行在 CPU 的部分，而 Device 端则是在 GPU 上运行的部分，如下图所示。</p>
<p><img src="/img/2017-10-16-Image-4.png" alt=""></p>
<p>在程序执行过程中，通常 Host 端程序会将数据在主内存中准备好并复制到显存，再由 GPU 执行 Device 端程序，完成后再由 Host 端程序将结果从显存拷贝至主内存。由于 CPU 存取显存时只能通过 PCI Express 接口，因此速度较慢（PCI Express x16 的理论带宽是双向各 4 GB/s），因此不能太频繁的执行这类操作，以免降低效率。</p>
<p>在 CUDA  架构下，GPU 执行时的最小单元是 Thread，数个 Thread 可以组成一个 Block ，<strong>一个 Block 中的 Thread 能够存取同一块共享的内存，而且可以快速进行同步操作</strong>。每一个 Block 所能包含的 Thread 数目是有限的，但是执行相同程序的 Block 可以组成 Grid。不同 Block 中的 Thread 无法存取同一个共享内存，因此无法进行通信和同步。</p>
<p>由于 GPU 具备大量适用于并行计算的特性，因此 GPU 处理问题的方式和 CPU 是不同的，主要体现在以下两点。</p>
<ul>
<li>内存存取 latency 的问题：CPU 通常使用 Cache 开减少存取主内存的次数，以避免内存 latency 影响到执行效率。GPU 通常没有 Cache（或很小），其利用并行化的方式来隐藏内存的 latency（当一个 Thread 需要等待内存读取时，开始执行另一个 Thread）。</li>
<li>分支指令的问题：CPU 通常利用分支预测等方式来减少分支指令造成的 pipeline bubble。GPU 则多半使用类似处理内存 latency 的方式。不过，通常 GPU 处理分支的效率会比较差。</li>
</ul>
<h3 id="Section-1-Sum-of-Squares"><a href="#Section-1-Sum-of-Squares" class="headerlink" title="Section 1: Sum of Squares"></a>Section 1: Sum of Squares</h3><p><strong>目标</strong>：对于给定数组，利用 CUDA 编程实现对该数组所有元素的平方进行求和，并计算每次求和<strong>所消耗的时间</strong>及<strong>显存带宽</strong>。</p>
<p>我们首先实现在 GPU 上的串行求和程序，然后将串行程序并行化，并从两个维度对并行程序进行优化。</p>
<h4 id="Step-1-CUDA初始化"><a href="#Step-1-CUDA初始化" class="headerlink" title="Step 1: CUDA初始化"></a>Step 1: CUDA初始化</h4><p>首先实验需要使用 CUDA 的 RunTime API，所以需要引入头文件 <code>cuda_runtime.h</code>。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// CUDA Runtime API</span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cuda_runtime.h&gt;</span></span></div></pre></td></tr></table></figure>
<p>编写程序对当前环境进行检测，如果存在支持 CUDA 的设备，需要设置相应的设备。如下所示。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* CUDA初始化 */</span></div><div class="line"><span class="function"><span class="keyword">bool</span> <span class="title">initCUDA</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> count, i;</div><div class="line">    <span class="comment">// 取得支持CUDA的装置的数目</span></div><div class="line">    cudaGetDeviceCount(&amp;count);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (<span class="number">0</span> == count) &#123;</div><div class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"There is no device.\n"</span>);</div><div class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; count; i++) &#123;</div><div class="line">        cudaDeviceProp prop;</div><div class="line">        <span class="keyword">if</span> (cudaGetDeviceProperties(&amp;prop, i) == cudaSuccess) &#123;</div><div class="line">            <span class="keyword">if</span> (prop.major &gt;= <span class="number">1</span>) &#123;</div><div class="line">                <span class="keyword">break</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (i == count) &#123;</div><div class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"There is no device.\n"</span>);</div><div class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    cudaSetDevice(i);</div><div class="line"></div><div class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这段程序首先调用<code>cudaGetDeviceCount</code>函数获取支持 CUDA 的设备的数量，如果不存在支持 CUDA 的设备 ，则会传入 1（ Device 0），Device 0 只是一个仿真设备，CUDA 的很多功能都不支持，因此如果要真正的确定是否存在支持 CUDA 的设备，需要对每个设备调用<code>cudaGetDeviceProperties</code>函数来获取具体的参数。</p>
<h4 id="Step-2-CUDA核函数"><a href="#Step-2-CUDA核函数" class="headerlink" title="Step 2: CUDA核函数"></a>Step 2: CUDA核函数</h4><p>在介绍核函数前，通过一段程序创建待求和的数组，如下所示。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* 产生0-9之间的随机数 */</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">generateNumbers</span><span class="params">(<span class="keyword">int</span> *numbers, <span class="keyword">int</span> size)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> i;</div><div class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; size; i++) &#123;</div><div class="line">        numbers[i] = rand() % <span class="number">10</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果要进行求和计算，需要将生成的数组从主内存拷贝至显存。因此，我们需要在显存开辟一块合适的空间，然后将数组拷贝至显存空间，相关代码如下。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> *gpudata, *result;</div><div class="line"></div><div class="line">generateNumbers(data, DATA_SIZE);</div><div class="line"></div><div class="line"><span class="comment">// 在显存上分配空间</span></div><div class="line"><span class="comment">// 思考：为什么cudaMalloc函数原型的第一个参数类型为 (void **)？</span></div><div class="line"><span class="comment">// 原因：gpudata指向某块内存区域的首地址，cudaMalloc在显存中分配一块内存，然后将该内存区域的首地址</span></div><div class="line"><span class="comment">//      赋值给gpudata，因此cudaMalloc修改的是gpudata本身的值，而不是gpudata指向的内存区域的值。</span></div><div class="line">cudaMalloc((<span class="keyword">void</span>**)&amp;gpudata, <span class="keyword">sizeof</span>(<span class="keyword">int</span>) * DATA_SIZE);</div><div class="line">cudaMalloc((<span class="keyword">void</span>**)&amp;result, <span class="keyword">sizeof</span>(<span class="keyword">int</span>));</div><div class="line"></div><div class="line"><span class="comment">// 将数据从内存复制到显存</span></div><div class="line">cudaMemcpy(gpudata, data, <span class="keyword">sizeof</span>(<span class="keyword">int</span>) * DATA_SIZE, cudaMemcpyHostToDevice);</div></pre></td></tr></table></figure>
<p>在完成主内存和显存的数据拷贝后，开始着手编写核函数实现在 GPU 上的求和计算，核函数在编写时需要在函数返回值（<code>void</code>）加添加<code>__global__</code>，同时，核函数不允许有返回值。目前我们仅实现串行求和，其核函数如下所示。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* 计算平方和（__global__函数运行于GPU）*/</span></div><div class="line">__<span class="function">global__ <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sumOfSquares</span><span class="params">(<span class="keyword">int</span> *numbers, <span class="keyword">int</span> *result)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> sum, i;</div><div class="line">    sum = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; DATA_SIZE; i++) &#123;</div><div class="line">        sum += numbers[i] * numbers[i];</div><div class="line">    &#125;</div><div class="line">    *result = sum;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="Step-3-执行核函数"><a href="#Step-3-执行核函数" class="headerlink" title="Step 3: 执行核函数"></a>Step 3: 执行核函数</h4><p>在 CUDA 中，使用如下规则执行核函数。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">函数名称&lt;&lt;&lt;Block Num, Thread Num, Shared Memory Size&gt;&gt;&gt;(参数...);</div></pre></td></tr></table></figure>
<p>因为目前我们仅需要实现串行计算，因此设置Block Num = 1，Thread Num = 1，Shared Memory Size = 0，相关程序如下所示。同时，在执行核函数后不要忘记释放程序分配的显存。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sumOfSquares &lt;&lt; &lt; <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span> &gt;&gt; &gt; (gpudata, result);</div><div class="line"><span class="comment">// 把计算结果从显存复制到内存</span></div><div class="line">cudaMemcpy(&amp;sum, result, <span class="keyword">sizeof</span>(<span class="keyword">int</span>), cudaMemcpyDeviceToHost);</div><div class="line">cudaFree(gpudata);</div><div class="line">cudaFree(result);</div></pre></td></tr></table></figure>
<p>Step 1，Step 2 和 Step 3 的完整程序<code>sum_squares_1.cu</code>见 <a href="https://github.com/tinylcy/cuda_lab/blob/master/SumSquares/sum_squares_1.cu" target="_blank" rel="external">GitHub</a> 。</p>
<h4 id="Step-4-评估程序表现"><a href="#Step-4-评估程序表现" class="headerlink" title="Step 4: 评估程序表现"></a>Step 4: 评估程序表现</h4><p>在介绍 CUDA 架构时提到，GPU 通常没有 Cache（或很小），因此我们在编写程序时需要避免内存 latency 影响到执行效率。<strong>本实验通过核函数的运行时间来计算程序所使用的显存带宽在评估程序的性能表现。</strong></p>
<p>对<code>sum_squares_1.cu</code>进行部分改动：利用<code>clock</code>函数获取当前时间，时间差值即为核函数的运行时间。相关代码如下。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* 计算平方和（__global__函数运行于GPU）*/</span></div><div class="line">__<span class="function">global__ <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sumOfSquares</span><span class="params">(<span class="keyword">int</span> *numbers, <span class="keyword">int</span> *result, <span class="keyword">clock_t</span> *time)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> sum, i;</div><div class="line">    <span class="keyword">clock_t</span> start, end;</div><div class="line"></div><div class="line">    <span class="comment">// 获取起始时间</span></div><div class="line">    start = clock();</div><div class="line"></div><div class="line">    sum = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; DATA_SIZE; i++) &#123;</div><div class="line">        sum += numbers[i] * numbers[i];</div><div class="line">    &#125;</div><div class="line">    *result = sum;</div><div class="line"></div><div class="line">    <span class="comment">// 获取结束时间</span></div><div class="line">    end = clock();</div><div class="line"></div><div class="line">    *time = end - start;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>由于核函数不能有返回值，因此在显存开辟一块空间来保存运行时间，然后将该运行时间值拷贝至内存。注意，该时间值的单位是时钟周期，我们需要将消耗的时钟周期数除以 GPU 自身的频率得到以秒为单位的时间值。</p>
<p>对于显存带宽的计算，整个过程程序传输的数据量大小为 4 <em> 1024 </em> 1024 Bytes，将其除以时间得到程序运行过程中占用的显存带宽。</p>
<p>Step 4 的完整程序 <code>sum_squares_2.cu</code> 见 <a href="https://github.com/tinylcy/cuda_lab/blob/master/SumSquares/sum_squares_2.cu" target="_blank" rel="external">GitHub</a>。</p>
<h4 id="Step-5-串行程序并行化"><a href="#Step-5-串行程序并行化" class="headerlink" title="Step 5: 串行程序并行化"></a>Step 5: 串行程序并行化</h4><p>在 CUDA 中，数据是从主内存复制到显存的 Global Memory，而Global Memory 是没有 Cache 的 ，因此存取 Global Memory 所需要的时间是非常长的（通常有数百个时钟周期）。由于之前的程序只有一个线程，当线程读取 Global Memory 时，线程会等待至实际数据读取成功，才能进行下一步计算。</p>
<p>如果程序有多个线程，当其中一个线程在等待读取 Global Memory 时，GPU 可以立即切换至另一个线程。因此，通过增加线程的数量来提高显存的带宽是有效的策略。</p>
<p>首先在程序中定义线程的数量，如下所示。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 线程数</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> THREAD_NUM 256</span></div></pre></td></tr></table></figure>
<p>程序将数组划分为 <code>THREAD_NUM</code>段，每个线程负责计算其中一段。最后，CPU 负责将各个线程计算得到的子结果进行累加。相关代码如下。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* 计算平方和（__global__函数运行于GPU）*/</span></div><div class="line">__<span class="function">global__ <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sumOfSquares</span><span class="params">(<span class="keyword">int</span> *numbers, <span class="keyword">int</span> *sub_sum, <span class="keyword">clock_t</span> *time)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> i;</div><div class="line">    <span class="comment">// 获取当前线程Id（从0开始）</span></div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> thread_id = threadIdx.x;</div><div class="line">    <span class="comment">// 每个线程累加元素的个数</span></div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> size = DATA_SIZE / THREAD_NUM;</div><div class="line"></div><div class="line">    sub_sum[thread_id] = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span> (i = thread_id * size; i &lt; (thread_id + <span class="number">1</span>) * size; i++) &#123;</div><div class="line">        sub_sum[thread_id] += numbers[i] * numbers[i];</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Step 5 的完整程序<code>sum_squares_3.cu</code>见 <a href="https://github.com/tinylcy/cuda_lab/blob/master/SumSquares/sum_squares_3.cu" target="_blank" rel="external">GitHub</a>。</p>
<h4 id="Step-6-改进显存存取模式"><a href="#Step-6-改进显存存取模式" class="headerlink" title="Step 6: 改进显存存取模式"></a>Step 6: 改进显存存取模式</h4><p>显卡内存一般都是 DRAM，因此最有效的显存存取方式为连续存取。对于<code>cuda_sample_3</code>，虽然每个线程操作的都是一块连续的内存，但是考虑当一个线程等待 Global Memory 的数据时，GPU 切换至另一个线程，而另一个线程会从显存的其它位置存取数据，下图描述了上述过程。</p>
<p><img src="/img/2017-10-16-Image-5.png" alt=""></p>
<p>综上分析，虽然在同一个线程中是在一块连续的显存空间读取数据，但是在实际执行时并不是连续读取的，而是跳跃式的存取模式。因此，我们需要将显存的存取模式改进为连续存取模式，如下图所示。</p>
<p><img src="/img/2017-10-16-Image-6.png" alt=""></p>
<p>修改核函数，改进显存的存取模式，相关程序如下。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* 计算平方和（__global__函数运行于GPU）*/</span></div><div class="line">__<span class="function">global__ <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sumOfSquares</span><span class="params">(<span class="keyword">int</span> *numbers, <span class="keyword">int</span> *sub_sum, <span class="keyword">clock_t</span> *time)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> i;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> thread_id = threadIdx.x;</div><div class="line">  </div><div class="line">    sub_sum[thread_id] = <span class="number">0</span>;</div><div class="line">    <span class="comment">// 线程0获取第0个元素，线程1获取第1个元素，以此类推... </span></div><div class="line">    <span class="keyword">for</span> (i = thread_id; i &lt; DATA_SIZE; i += THREAD_NUM) &#123;</div><div class="line">        sub_sum[thread_id] += numbers[i] * numbers[i];</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Step 6 的完整程序<code>sum_squares_4.cu</code>见 <a href="https://github.com/tinylcy/cuda_lab/blob/master/SumSquares/sum_squares_4.cu" target="_blank" rel="external">GitHub</a>。</p>
<h4 id="Step-7-进一步并行"><a href="#Step-7-进一步并行" class="headerlink" title="Step 7: 进一步并行"></a>Step 7: 进一步并行</h4><p>在介绍 CUDA 架构时提到，CUDA 除了提供了 Thread，还提供了 Block 及 Grid等重要的机制。每个 Block 的数量是有限的，但是可以通过增加 Block 的数量来成倍的增加线程的数量。需要注意的是，不同 Block 内的线程相互不能同步和通信，不过在我们的程序中线程之间并不需要进行同步或通信。因此，Step 7 将会使用多个 Block 来进一步并行化程序。相关代码如下。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* 计算平方和（__global__函数运行于GPU）*/</span></div><div class="line">__<span class="function">global__ <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sumOfSquares</span><span class="params">(<span class="keyword">int</span> *numbers, <span class="keyword">int</span> *sub_sum, <span class="keyword">clock_t</span> *time)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> i;</div><div class="line">    <span class="comment">// 获取当前线程所属的Block号（从0开始）</span></div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> block_id = blockIdx.x;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> thread_id = threadIdx.x;</div><div class="line"></div><div class="line">    sub_sum[block_id * THREAD_NUM + thread_id] = <span class="number">0</span>;</div><div class="line">    <span class="comment">// Block0-线程0获取第0个元素，Block0-线程1获取第1个元素...Block1-线程0获取第THREAD_NUM个元素，以此类推... </span></div><div class="line">    <span class="keyword">for</span> (i = block_id * THREAD_NUM + thread_id; i &lt; DATA_SIZE; i += BLOCK_NUM * THREAD_NUM) &#123;</div><div class="line">        sub_sum[block_id * THREAD_NUM + thread_id] += numbers[i] * numbers[i];</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Step 7 的完整程序<code>sum_squares_5.cu</code>见 <a href="https://github.com/tinylcy/cuda_lab/blob/master/SumSquares/sum_squares_5.cu" target="_blank" rel="external">GitHub</a>。</p>
<h4 id="Step-8-共享内存和线程同步"><a href="#Step-8-共享内存和线程同步" class="headerlink" title="Step 8: 共享内存和线程同步"></a>Step 8: 共享内存和线程同步</h4><p>在 Step 7 中，CPU 需要进行 <code>BLOCK_NUM * THREAD_NUM</code> 个元素的累加，如果可以让 GPU 执行一部分的累加，理应能够进一步提高程序的并行度。因为在一个 Block 内，线程是可以共享内存的，因此可以在 GPU 上实现一个 Block 内的线程结果累加，CPU 仅需要完成各个 Block 的计算结果的累加。</p>
<p>需要注意：需要等待一个 Block 内的所有线程都完成计算才进行各个线程的计算结果的类型。因此，程序需要进行线程的同步，在 CUDA 中，通过<code>__syncthreads</code>函数进行线程的同步，相关代码如下。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* 计算平方和（__global__函数运行于GPU）*/</span></div><div class="line">__<span class="function">global__ <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sumOfSquares</span><span class="params">(<span class="keyword">int</span> *numbers, <span class="keyword">int</span> *sub_sum, <span class="keyword">clock_t</span> *time)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> i;</div><div class="line">    <span class="comment">// 声明共享内存区域，用于存储每个Block中线程计算结果的累加和</span></div><div class="line">    <span class="keyword">extern</span> __shared__ <span class="keyword">int</span> shared[];</div><div class="line"></div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> block_id = blockIdx.x;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> thread_id = threadIdx.x;</div><div class="line">  </div><div class="line">    shared[thread_id] = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (i = block_id * THREAD_NUM + thread_id; i &lt; DATA_SIZE; i += BLOCK_NUM * THREAD_NUM) &#123;</div><div class="line">        shared[thread_id] += numbers[i] * numbers[i];</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 线程同步，所有线程需要执行到此处方可继续向下执行</span></div><div class="line">    __syncthreads();</div><div class="line"></div><div class="line">    <span class="comment">// 线程0负责计算所有线程的计算结果累加和</span></div><div class="line">    <span class="keyword">if</span> (<span class="number">0</span> == thread_id) &#123;</div><div class="line">        <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; THREAD_NUM; i++) &#123;</div><div class="line">            shared[<span class="number">0</span>] += shared[i];</div><div class="line">        &#125;</div><div class="line">        sub_sum[block_id] = shared[<span class="number">0</span>];</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Step 8 的完整程序<code>sum_squares_6.cu</code>见 <a href="https://github.com/tinylcy/cuda_lab/blob/master/SumSquares/sum_squares_6.cu" target="_blank" rel="external">GitHub</a>。</p>
<h4 id="Step-9-树状加法"><a href="#Step-9-树状加法" class="headerlink" title="Step 9: 树状加法"></a>Step 9: 树状加法</h4><p>在 Step 8 中，一个 Block 中所有线程的结果的累加是通过一个线程（Thread 0）实现的，如果能够把每个 Block 内的加法并行化，那么程序的并行度应该能够进一步提高。我们利用树状加法将加法并行，树状加法计算过程如下图所示。</p>
<p><img src="/img/2017-10-16-Image-7.png" alt=""></p>
<p>上图一个格子代表一个线程的计算结果，当进行第一轮迭代时，步长等于 1，Thread 0 和 Thread 1 相加，Thread 2 和 Thread 3 相加，依次类推…当进行第二轮迭代时，步长等于 1 + 1 = 2，Thread 0 和 Thread 2 相加，Thread 4 和 Thread 6 相加，依次类推…当进行第三轮迭代时，步长等于 2 + 2 = 4， Thread 0 和 Thread 4 相加，Thread 8 和 Thread 12 相加…依次类推。相关代码如下。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* 计算平方和（__global__函数运行于GPU）*/</span></div><div class="line">__<span class="function">global__ <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sumOfSquares</span><span class="params">(<span class="keyword">int</span> *numbers, <span class="keyword">int</span> *sub_sum, <span class="keyword">clock_t</span> *time)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> i;</div><div class="line"></div><div class="line">    <span class="keyword">extern</span> __shared__ <span class="keyword">int</span> shared[];</div><div class="line"></div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> block_id = blockIdx.x;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> thread_id = threadIdx.x;</div><div class="line">    <span class="comment">// 定义步长和计算掩码</span></div><div class="line">    <span class="keyword">int</span> offset, mask;</div><div class="line">  </div><div class="line">    shared[thread_id] = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span> (i = block_id * THREAD_NUM + thread_id; i &lt; DATA_SIZE; i += BLOCK_NUM * THREAD_NUM) &#123;</div><div class="line">        shared[thread_id] += numbers[i] * numbers[i];</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    __syncthreads();</div><div class="line"></div><div class="line">    <span class="comment">/* 并行加法代码段 */</span></div><div class="line">    offset = <span class="number">1</span>;</div><div class="line">    mask = <span class="number">1</span>;</div><div class="line">    <span class="keyword">while</span> (offset &lt; THREAD_NUM) &#123;</div><div class="line">        <span class="comment">// 注意 &amp; 的优先级小于 ==</span></div><div class="line">        <span class="keyword">if</span> ((thread_id &amp; mask) == <span class="number">0</span> &amp;&amp; thread_id + offset &lt; THREAD_NUM) &#123;</div><div class="line">            shared[thread_id] += shared[thread_id + offset];</div><div class="line">        &#125;</div><div class="line">        offset += offset;</div><div class="line">        mask += offset;</div><div class="line">        <span class="comment">// 每迭代一轮需要所有线程进行一次同步</span></div><div class="line">        __syncthreads();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    sub_sum[block_id] = shared[<span class="number">0</span>];</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Step 9 的完整程序<code>sum_squares_7.cu</code>见 <a href="https://github.com/tinylcy/cuda_lab/blob/master/SumSquares/sum_squares_7.cu" target="_blank" rel="external">GitHub</a>。</p>
<h3 id="Section-2-Matrix-Multiplication"><a href="#Section-2-Matrix-Multiplication" class="headerlink" title="Section 2: Matrix Multiplication"></a>Section 2: Matrix Multiplication</h3><p>目标：利用 CUDA 编写矩阵乘法并行程序，为了简化程序编写，假设待相乘的两个矩阵均为方块矩阵。</p>
<p>在 CUDA 上实现矩阵乘法有多种方法，我自己实现了一个<a href="https://github.com/tinylcy/cuda_lab/blob/master/MatrixMultiplication/matrix_multiplication.cu" target="_blank" rel="external">版本</a>，供参考。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a href="http://blog.csdn.net/column/details/computervision.html" target="_blank" rel="external">计算机视觉编程</a></li>
<li><a href="http://www.smallgui.com/wp-content/uploads/2016/04/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%B0%88CUDA.pdf" target="_blank" rel="external">深入浅出谈 CUDA</a></li>
</ul>
</div><div class="tags"><a href="/tags/CUDA/">CUDA</a></div><div class="post-nav"><a href="/2017/07/12/初探Webx之约定胜于配置/" class="pre">初探Webx之约定胜于配置</a></div><div id="disqus_thread"><script>var disqus_shortname = 'tinylcy';
var disqus_identifier = '2017/10/16/CUDA-Lab-Sum-of-Squares-Matrix-Multiplication/';
var disqus_title = 'CUDA Lab: Sum of Squares &amp; Matrix Multiplication';
var disqus_url = 'http://tinylcy.me/2017/10/16/CUDA-Lab-Sum-of-Squares-Matrix-Multiplication/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//tinylcy.disqus.com/count.js" async></script></div><div class="post-reward"><div id="reward_board" class="reward_bar center"><a id="btn_reward" href="javascript:;" title="打赏" class="btn_reward"></a><div class="reward_txt">好心的朋友，我是在做买卖 :)<br></div></div><div id="reward_guide" class="reward_bar center hidden"><img src="/img/wechat.png" title="微信打赏"></div><script type="text/javascript">document.getElementById('btn_reward').onclick = function(){
    $('#reward_board').addClass('hidden');
    $('#reward_guide').removeClass('hidden');
}</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://tinylcy.me"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Unix-Linux/" style="font-size: 15px;">Unix/Linux</a> <a href="/tags/Life/" style="font-size: 15px;">Life</a> <a href="/tags/6-824/" style="font-size: 15px;">6.824</a> <a href="/tags/CSAPP/" style="font-size: 15px;">CSAPP</a> <a href="/tags/Assembly/" style="font-size: 15px;">Assembly</a> <a href="/tags/JDK/" style="font-size: 15px;">JDK</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/DistributedSystems/" style="font-size: 15px;">DistributedSystems</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/Spring/" style="font-size: 15px;">Spring</a> <a href="/tags/C/" style="font-size: 15px;">C</a> <a href="/tags/CUDA/" style="font-size: 15px;">CUDA</a> <a href="/tags/TCP-IP/" style="font-size: 15px;">TCP/IP</a> <a href="/tags/Webx/" style="font-size: 15px;">Webx</a> <a href="/tags/Golang/" style="font-size: 15px;">Golang</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://wdxtub.com/" title="wdxtub" target="_blank">wdxtub</a><ul></ul><a href="http://brianway.github.io/" title="brianway" target="_blank">brianway</a><ul></ul><a href="http://www.yinwang.org" title="yinwang" target="_blank">yinwang</a><ul></ul><a href="http://coolshell.cn/" title="coolshell" target="_blank">coolshell</a><ul></ul><a href="http://lucida.me/" title="lucida" target="_blank">lucida</a><ul></ul><a href="http://mindhacks.cn/" title="mindhacks" target="_blank">mindhacks</a><ul></ul><a href="http://mindwind.me/" title="mindwind" target="_blank">mindwind</a><ul></ul><a href="http://lifeofzjs.com/" title="lifeofzjs" target="_blank">lifeofzjs</a><ul></ul><a href="http://papwin.com/" title="潘岸平的獨立博客" target="_blank">潘岸平的獨立博客</a><ul></ul><a href="http://www.zreading.cn/" title="左岸读书" target="_blank">左岸读书</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a>2017 </a><a href="/." rel="nofollow">tinylcy.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>